{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f04a219-712b-436b-a29d-ee0cc694a35a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Molecular generation when the pharmacophore is given in coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747f6f6",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c734d9-fd87-4c27-be19-6994bf6f378a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: parameter(s) not used: in,latent_dim,latent_heads,out\n",
      "reloading model weights from ./output/chembl_test/rs_mapping_2/rs_mapping/fold0_epoch32.pth...\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from model.pgmg import PGMG\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "import pickle\n",
    "import dgl\n",
    "import einops\n",
    "import pandas as pd\n",
    "MODEL_PATH = \"./output/chembl_test/rs_mapping_2/rs_mapping/fold0_epoch32.pth\"\n",
    "TOKENIZER_PATH = \"./output/chembl_test/rs_mapping_2/rs_mapping/tokenizer_r_iso.pkl\" \n",
    "OUTPUT_DIR = Path(f'./output/')\n",
    "path='./phar_example/'\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    \n",
    "    n_mols = -1  # number of molecules used to build pharmacophore models\n",
    "    n_pp_per_mol = 1  # number of pharmacophores \n",
    "    n_repeat = 10\n",
    "    \n",
    "    reload_ignore=['pos_encoding']\n",
    "    \n",
    "    gen_batch_size = 256\n",
    "    n_workers = 12\n",
    "\n",
    "def init_logger(log_path=OUTPUT_DIR, logger_name='main'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(logger_name)\n",
    "    logger.setLevel(INFO)\n",
    "    logger.handlers.clear()\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_path / f'log')\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "LOGGER = init_logger(OUTPUT_DIR)\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch(seed=CFG.seed)    \n",
    "    \n",
    "with open(TOKENIZER_PATH,'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "model_setting = {\n",
    "    \"max_len\": 128,\n",
    "    \"pp_v_dim\": 7 + 1,\n",
    "    \"pp_e_dim\": 1,\n",
    "    \"pp_encoder_n_layer\": 4,\n",
    "    \"hidden_dim\": 384,\n",
    "    \"latent_heads\": 8,  # 试试看\n",
    "    \"latent_dim\": 384,\n",
    "    \"n_layers\": 8,\n",
    "    \"ff_dim\": 1024,\n",
    "    \"n_head\": 8,\n",
    "    \"init_token_num\": 8,\n",
    "    \"kernel_size\": 3,  # used only in logging\n",
    "    \"non_expand\": True,\n",
    "    'in': 'rs',\n",
    "    'out': 'rs',\n",
    "}\n",
    "model_path = MODEL_PATH\n",
    "model_params = dict(model_setting)\n",
    "\n",
    "model = PGMG(model_params, tokenizer)\n",
    "model.to('cuda:0')\n",
    "LOGGER.info(f'reloading model weights from {model_path}...')\n",
    "states = torch.load(model_path, map_location='cuda:0')\n",
    "states['model'].update({k:model.state_dict()[k] for k in model.state_dict().keys() \n",
    "                    if k.startswith(tuple(CFG.reload_ignore))})\n",
    "LOGGER.info(model.load_state_dict(states['model'], strict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a8f41-e4e8-4222-8a44-5a66e724b1be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# preprocess .phar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98b0d78-8074-4f40-b3bb-0856968efb2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def _onek_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return [x == s for s in allowable_set]\n",
    "\n",
    "def _atom_features(atom):\n",
    "    ELEM_LIST = [[1],[2],[3],[4],[5],[6],[7]]\n",
    "    return (torch.HalfTensor(_onek_encoding_unk(atom, ELEM_LIST)))\n",
    "\n",
    "def eucliDist(A,B):\n",
    "    return math.sqrt(sum([(a - b)**2 for (a,b) in zip(A,B)]))\n",
    "\n",
    "def mappingDist(eucli_Dist):\n",
    "    mapping_dist=0.0018*(eucli_Dist**2)+0.9731*eucli_Dist-0.1179\n",
    "    return mapping_dist\n",
    "\n",
    "\n",
    "def sample_probability(elment_array,plist,N):\n",
    "    Psample=[]\n",
    "    n=len(plist)\n",
    "    index=int(random.random()*n)\n",
    "    mw=max(plist)\n",
    "    beta=0.0\n",
    "    for i in range(N):                  ##核心算法\n",
    "        beta=beta+random.random()*2.0*mw\n",
    "        while beta > plist[index]:\n",
    "            beta=beta-plist[index]\n",
    "            index=(index+1)%n\n",
    "        Psample.append(elment_array[index])\n",
    "    cresult=Counter(Psample)\n",
    "    psam=[cresult[x] for x in plist]\n",
    "    pe=[x*N for x in plist]\n",
    "    return Psample    \n",
    "\n",
    "\n",
    "def preprocess_phar(path):\n",
    "    files= os.listdir(path)\n",
    "    uni_phar=[]\n",
    "    g_list=[]\n",
    "    mol_phco_list=[]\n",
    "    for i in (range(len(files))):#len(files)\n",
    "        mol_phco=[]\n",
    "        dist_index_u=[]\n",
    "        dist_index_v=[]\n",
    "        dist_mapping=[]\n",
    "        file_name=files[i]\n",
    "        f=open(path+file_name, encoding='gbk')\n",
    "        data = f.readlines()\n",
    "        for j in range(1,len(data)-1):\n",
    "            line=(data)[j].split('\\t')\n",
    "            if line[0]!='EXCL':\n",
    "                phar_type=[line[0],float(line[4]),float(line[1]),float(line[2]),float(line[3])]\n",
    "                if line[0]=='AROM':  \n",
    "                    phar_type[0]=1\n",
    "                    num=[5,6]\n",
    "                    num_p=[0.5,0.5]\n",
    "                    num_=sample_probability(num,num_p,1)\n",
    "                    if num_[0]==5:\n",
    "                        phar_type[1]=5\n",
    "                    if num_[0]==6:\n",
    "                        phar_type[1]=6\n",
    "                if line[0]=='LIPO':\n",
    "                    num=['Hydrophobe','LumpedHydrophobe']\n",
    "                    num_p=[0.5,0.5]\n",
    "                    num_=sample_probability(num,num_p,1)\n",
    "                    if num_[0]=='Hydrophobe':\n",
    "                        phar_type[0]=2\n",
    "                        phar_type[1]=3\n",
    "                    if num_[0]=='LumpedHydrophobe':\n",
    "                        phar_type[0]=6\n",
    "                        phar_type[1]=6\n",
    "                if line[0]=='POSC':\n",
    "                    phar_type[0]=3\n",
    "                    phar_type[1]=1\n",
    "                if line[0]=='HACC':\n",
    "                    phar_type[0]=4\n",
    "                    phar_type[1]=1\n",
    "                if line[0]=='HDON':\n",
    "                    phar_type[0]=5##\n",
    "                    phar_type[1]=1\n",
    "                if line[0]=='NEGC':\n",
    "                    phar_type[0]=7\n",
    "                    phar_type[1]=1\n",
    "                mol_phco.append(phar_type)\n",
    "        type_list=[]\n",
    "        size_=[]\n",
    "        for elment in mol_phco:\n",
    "            type_list.append(_atom_features([elment[0]]))\n",
    "            size_.append(elment[1])\n",
    "        for ii in range(len(mol_phco)):\n",
    "            for jj in range(len(mol_phco)):\n",
    "                if ii!=jj:\n",
    "                    pos_i=mol_phco[ii][2:]\n",
    "                    pos_j=mol_phco[jj][2:]\n",
    "                    dist_ij=eucliDist(pos_i,pos_j)\n",
    "                    dist_index_u.append(ii)\n",
    "                    dist_index_v.append(jj)\n",
    "                    map_dist=mappingDist(dist_ij)\n",
    "                    dist_mapping.append(map_dist)\n",
    "\n",
    "        u_list_tensor=torch.tensor(dist_index_u)\n",
    "        v_list_tensor=torch.tensor(dist_index_v)\n",
    "        g=dgl.graph((u_list_tensor,v_list_tensor))\n",
    "        g.edata['dist']=torch.HalfTensor(dist_mapping)\n",
    "\n",
    "        type_list_tensor=torch.stack(type_list)\n",
    "        g.ndata['type']=type_list_tensor\n",
    "        g.ndata['size']=torch.HalfTensor(size_)\n",
    "        g_list.append(g)\n",
    "    return g_list\n",
    "    \n",
    "\n",
    "g1=preprocess_phar(path)\n",
    "gs=g1\n",
    "for g in gs:\n",
    "    a=g.ndata['type']\n",
    "    g.ndata['h'] = torch.cat((a,g.ndata['size'].reshape(-1, 1)), dim=1).float()\n",
    "    g.edata['h'] = g.edata['dist'].reshape(-1, 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c6461-298c-4ee1-81f6-aa6b794f92ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3089eee8-d708-4c64-b100-4b57c1b80998",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[max sampling]\n",
      "resetting random seed...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5e484e7a7443af91c7d1d1fe68a5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gsx = gs*40\n",
    "bgx = dgl.batch(gsx).to('cuda')\n",
    "\n",
    "GEN_RESULT_DIR = OUTPUT_DIR\n",
    "GEN_RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "LOGGER.info('[max sampling]')\n",
    "\n",
    "LOGGER.info(f'resetting random seed...')\n",
    "seed_torch(CFG.seed)\n",
    "\n",
    "res = []\n",
    "for _ in tqdm(range(5)):\n",
    "    predictions = model.generate(bgx, random_sample=False)\n",
    "    res.extend(tokenizer.get_text(predictions))\n",
    "\n",
    "gen_result = einops.rearrange(np.array(res),'(a b)->a b',b=len(gs))\n",
    "pd.DataFrame(gen_result).T.reset_index().to_csv(GEN_RESULT_DIR/f'result_ePharmaLib_example.csv',index=False)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "LOGGER.info('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa31cf-0e9a-4272-9e5c-dbddd69827bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
